I"XŒ<p>Searching and sorting are atomic concepts in Computer Science, and 
something I didnâ€™t realise was going to be such a big thing before
I learned to code. Efficient methods for rifling through data, or sorting
it into order are gold dust. Thinking about the number of times
your implementation is completely reliant on accessing data, you quickly
realise how critical doing these basic operations quickly and accurately
can be in <em>any</em> algorithm.</p>

<p>As a beginner to CS, Iâ€™m going to attempt to summarise and analyse the
major algorithms one should be aware of in this post. I think they are
generally fairly easy to understand and implement, and critical for those
tech interviews where you have to reason between your quick and 
merge sorts.</p>

<p>Iâ€™m going to go through them one by one. In general optimal data structure
choice is critical, however wherever I can Iâ€™m going to try and implement
the above algorithms on a Python list. This is largely for simplicity.</p>

<h2 id="selection-sort">Selection Sort</h2>

<h3 id="motivation">Motivation</h3>

<p>This is amongst the simplest sorting algorithms, however itâ€™s simplicity
comes with a cost, namely itâ€™s very expensive in terms of time to compute
in comparison with other more nuanced algorithms.</p>

<p>Weâ€™d probably never want to implement this algorithm on itâ€™s own, as itâ€™s
a bad choice compared to other sorting algorithms, but it could be useful
as a component in more complex sorts.</p>

<p>Letâ€™s motivate the algorithm with an example. Consider sorting a deck of
numbered cards. As a human, the easiest way to do this is by finding the
card with the lowest value and placing it at the beginning of the deck,
the proceeding to the card with the second lowest value, etc, until all
cards have been placed.</p>

<h3 id="implementation">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">smallest</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
    <span class="s">"""
    Find the smallest element of a list, by iterating through the
        whole list.
    """</span>
    <span class="n">idx_smallest</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">smallest</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">idx_smallest</span><span class="p">]</span>
    <span class="n">found</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">smallest</span><span class="p">:</span>
            <span class="n">smallest</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">idx_smallest</span> <span class="o">=</span> <span class="n">i</span>

        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
            <span class="n">found</span> <span class="o">=</span> <span class="bp">True</span> 

    <span class="k">return</span> <span class="n">idx_smallest</span><span class="p">,</span> <span class="n">smallest</span>

 
<span class="k">def</span> <span class="nf">selection_sort</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
    <span class="s">"""
    Sort by continuously finding the next smallest element and putting
        that at the appropriate index.
    """</span>

    <span class="n">ordered</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">ordered</span><span class="p">:</span>

        <span class="n">idx_smallest</span><span class="p">,</span> <span class="n">val_smallest</span> <span class="o">=</span> <span class="n">smallest</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
        <span class="k">if</span> <span class="n">val_smallest</span> <span class="o">&lt;=</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">idx_smallest</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">idx_smallest</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
            <span class="n">ordered</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">return</span> <span class="n">l</span>
</code></pre></div></div>

<h3 id="analysis">Analysis</h3>

<p>As a minimum this algorithm will operate in $O(N^2)$ in the worst and 
average case. We can see this as being due to the need to iterate through
the whole list $(N-i)$ times at the $i^{th}$ timestep in the sort in order to
find the next smallest element. Giving a leading order complexity of $O(N^2)$
We can perform the entire sort in-place so we only take up $O(1)$ memory.</p>

<h2 id="merge-sort">Merge Sort</h2>

<p>This is an interview classic. Importantly merge-sort follows the â€˜divide
and conquerâ€™ paradigm for solving problems. This boils down to â€˜dividingâ€™
your problem into approachable sub-problems, solving these, and combiningâ€™
the sub-problem solutions together into a final solution.</p>

<p>Merge sort closely follows this paradigm. Intuitively, it operates by
dividing an $n$ element list into two subsequences of $\frac{n}{2}$ elements each,
sorting the subsequences, and finally merging the results. The recursion
has a base case of when you have a list of only a single element which is
already sorted.</p>

<p>Our major motivation here is to save on time-complexity, and the recursive
division of our problem space gives us a clue to it being significantly
less than $O(N^2)$ like for selection sort. However, an implementation
example should clarify this.</p>

<p>To understand the merge operation a didactic example is sorting a deck
of cards. Imagine two piles of cards, picking one up off one pile and
one off the the other pile, comparing the two values and placing face
down in a third pile the smallest card. We do this until one of the first
two piles are empty, at which point we place the remaining cards from the
non-empty pile down on the third pile.</p>

<p>We can sort by dividing the array to be sorted into two, and recursively
calling sort on the two portions, finally merging the results.</p>

<h3 id="implementation-1">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="s">"""
    Iterative merge operation.
    """</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">left</span><span class="p">)</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">right</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">left</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">right</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">left</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">right</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">j</span><span class="o">+=</span><span class="mi">1</span>

    <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">left</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
    <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">right</span><span class="p">[</span><span class="n">j</span><span class="p">:])</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
    <span class="s">"""
    Recursively defined sort.
    """</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">l</span>

    <span class="n">mid</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">left</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">l</span><span class="p">[:</span><span class="n">mid</span><span class="p">])</span>
    <span class="n">right</span> <span class="o">=</span> <span class="n">merge_sort</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="n">mid</span><span class="p">:])</span>

    <span class="k">return</span> <span class="n">merge</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-1">Analysis</h3>

<p>The implementation above is very neat, and pretty much directly translated
from the pseudocode in <a href="https://en.wikipedia.org/wiki/Introduction_to_Algorithms">CLRS</a> 
(a book you should check out beyond this post).</p>

<p>What kind of complexity can we expect with this algorithm? Well, to get
an idea we can estimate the number of elements in the recursion tree. This
will give us an indication of the number of operations taking place, and
therefore a time complexity. Inductively, we can infer that there are
$\log(N) + 1$ levels in the recursion tree. For example, a list of length 1
would have $\log(1) + 1 = 0$ levels, as we only call the <code class="highlighter-rouge">merge_sort</code> function
once. Furthermore, the complexity of the merge operation is $O(N)$ as we
may have to iterate through the whole list in order to merge. So total
complexity can be seen to be $O(N(\log(N) + 1)) = O(N\log(N))$. Space
complexity is $O(N)$ due to the need to store the result of the merge
operation.</p>

<h2 id="quick-sort">Quick Sort</h2>

<p>Merge sort has a wasteful bit of memory usage in that we need to keep a
record of the merged results at each step. Quick sort lets us avoid this
by sorting in place. Itâ€™s worst case runtime is $O(N^2)$, however it has
an average case runtime of $O(N\log(N))$ - same as merge sort, and the worst
case can be avoided by a clever strategy on behalf of the programmer,
however this will be much easier to explain in code, so letâ€™s start with
the implementation.</p>

<p>Similar to merge sort, quick sort applies the â€˜divide-and-conquerâ€™
paradigm. However, in order to understand exactly how, we need to
understand the â€˜partitionâ€™ procedure first, which is critical to the
implementation of quick sort.</p>

<p>Partitioning is easier to grasp through an example. Consider the following
array:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># unpartitioned array
</span><span class="n">array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<p>Letâ€™s choose the last element 5, as the â€˜pivotâ€™. Weâ€™re going to try and
arrange the array such that when 5 is placed in itâ€™s correct index all
elements to itâ€™s left are smaller than or equal to it, and all elements
to itâ€™s right are greater than or equal to it:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># partitioned array
</span><span class="n">array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<p>Note that the array is still unsorted at this point.</p>

<p>The following function implements this partitioning:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">partition</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>
    <span class="s">"""Partition function capable of operating on sub-arrays"""</span>
    <span class="n">pivot</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">high</span><span class="p">]</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">low</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">l</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">pivot</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">l</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">high</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="n">high</span><span class="p">],</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div></div>

<p>I like to think of this as moving a dividing line up the array from left
to right (essentially the $i$ index above), and checking if everything to
the left of this line is smaller than the pivot element, which weâ€™ve chosen
to be the last element of the array. Once the for loop has completed $i$
will equal the number of swaps, hence elements, that are smaller than the
pivot - therefore will tell us where to place the pivot element, which
happens in the last line. Furthermore, this all happens in place on the array,
we just return the index of the pivot element.</p>

<p>Using this functionality, we can implement quick sort by recursively 
calling quicksort on partitioned arrays. The base case of partitioning an
array with a single/no elements just returning itself.</p>

<h3 id="implementation-2">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quick_sort</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>
    <span class="s">"""Recursive quick sort implementation."""</span>
    <span class="k">if</span> <span class="n">low</span> <span class="o">&lt;</span> <span class="n">high</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">partition</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
        <span class="n">quick_sort</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">quick_sort</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-2">Analysis</h3>

<p>We can see that weâ€™ve again used the divide-and-conquer paradigm, where
we divide with the partition function rather than naively down the middle
like with merge sort. But whatâ€™s the runtime for quick sort? Itâ€™s doing
quite a lot of complicated stuff, especially the partition function, so
we should be a little more careful in our analysis.</p>

<p>Starting with the partitioning, in the worst case. This occurs when we
the procedure produces a sub-problem to two with n elements and 0 elements
respectively for every partition i.e. our array is anti-sorted <code class="highlighter-rouge">[5, 4, 3, 2, 1]</code> 
Then the partitioning will be of $O(N^2)$. Therefore in the worst case
quick sort is as rubbish as insertion sort. However, this can be helped
with clever choices of pivot - for example just picking a random pivot
each time, or something that reflects the data you are actually trying to
sort just so that you arenâ€™t faced with this problem.</p>

<p>In the best case, weâ€™d get two partitioned sub-problems of equal size.
This is now of the same order of complexity as merge sort, as something
approximately the same is happening, just differently! This results in a
quick sort complexity of $O(N\log(N))$.</p>

<p>In fact, as detailed in <a href="https://en.wikipedia.org/wiki/Introduction_to_Algorithms">CLRS</a>
sub-problems have to be extremely unbalanced to not achieve something
approaching the best case performance, i.e. even if we get two sub-problems
of size $\frac{9N}{10}$ and $\frac{N}{10}$ weâ€™d still get $O(N\log(N))$ performance,
however this is definitely something to detail in another post. For now I hope youâ€™re
happy to use this as a fact.</p>

<h2 id="binary-search">Binary Search</h2>

<p>Binary search is very easy to understand and implement, and follows common
sense. Assuming our array is sorted (which we are now armed to implement!). 
We first check the middle item of an array if our element is there we return,
otherwise if our element is greater than this we check the top half using the
same procedure, or vice versa the bottom half, until we find our element.
This is quite naturally defined recursively.</p>

<h3 id="implementation-3">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">binary_search</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">element</span><span class="p">):</span>
    <span class="s">"""Recursive binary search implementation."""</span>
    <span class="n">mid</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    
    <span class="k">if</span> <span class="n">l</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">==</span> <span class="n">element</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mid</span>
    
    <span class="k">elif</span> <span class="n">l</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">element</span><span class="p">:</span>
        <span class="n">binary_search</span><span class="p">(</span><span class="n">l</span><span class="p">[:</span><span class="n">mid</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">element</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">binary_search</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">:],</span> <span class="n">element</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-3">Analysis</h3>

<p>We are cutting our problem space in two every time as we head down the
recursion tree. Therefore, the number of operations till we find our
element is the sum of $N + N/2 + N/4 + â€¦ + 1$, where for $N$ elements we do
$2^k$ operations, where k is the step. Hence weâ€™d have the relationship $2^k = N$ 
between the number of elements in our array and the number of steps, so
the runtime is $O(\log(N))$.</p>

<p>A good take away from this is that if your problem space is reducing in
size with each step itâ€™s complexity is likely to be log-ish.</p>

<h2 id="graph-search">Graph Search</h2>

<p>It is possible, probably, to implement these algorithms using Python lists
but to be honest itâ€™s not worth the effort, as it might just obfuscate
the logic of the algorithm - which is what Iâ€™m trying to get across. So
for this section Iâ€™m going to mix things up a little, and implement the
following algorithms defined against the following <code class="highlighter-rouge">Graph</code> data structure
Iâ€™ve just made up. Itâ€™s important to note that this is a convenience object
and doesnâ€™t really serve any purpose other purpose than didactic.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>


<span class="k">class</span> <span class="nc">Graph</span><span class="p">:</span>
    <span class="s">"""Represent graph using adjacency list"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="p">)</span>


<span class="n">g</span> <span class="o">=</span> <span class="n">Graph</span><span class="p">()</span>  <span class="c1"># create graph object
</span><span class="n">g</span><span class="p">[</span><span class="s">'a'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'b'</span> <span class="c1"># add nodes
</span></code></pre></div></div>

<p>If youâ€™re interested in how graphs are implemented check out <a href="``https://en.wikipedia.org/wiki/Introduction_to_Algorithms">CLRS</a>
, I canâ€™t sell this book enough. Here Iâ€™ve chosen to represent it with a
adjacency list, using Pythonâ€™s default dict object, which basically allows
one to have a dict with keys which are lists. Here the keys represent nodes
and the items in their lists represent adjacent nodes.</p>

<h2 id="depth-first-search">Depth First Search</h2>

<p>The defining feature of depth first search is that it exhausts a given
route through a graph until it tries the next one. I.e. it will look for
the children of a given node, and then one childâ€™s children and so on
until itâ€™s reached the end, before moving onto another branch. In terms
of a useful example, this would be a useful algorithm if we wanted to know
when two distant nodes are connected, in contrast to breadth-first search as 
weâ€™ll see, as it would prioritise getting to the target node in any way
possible ASAP.</p>

<h3 id="implementation-4">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">visit</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">visited</span><span class="p">):</span>
    <span class="n">visited</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>


<span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">visited</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""Operates on Graph objects"""</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">visited</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">visited</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">False</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">}</span>
    
    <span class="n">visit</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">[</span><span class="n">root</span><span class="p">]:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">visited</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
            <span class="n">dfs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-4">Analysis</h3>

<p>Depth-first search visits every vertex once and checks every edge in the
graph once. Therefore, DFS complexity is $O(V+E)$ This assumes that the graph
is represented as an adjacency list.</p>

<h2 id="breadth-first-search">Breadth First Search</h2>

<p>Consider the motivating example for depth first search, finding whether
two distant nodes are linked, similarly we might want to solve the converse
problem - are two nearby nodes linked - for which depth first search
would be rubbish. It might search most of the graph before realising that
they are in fact next to each other! Breadth first search solves this
problem by checking all of the child nodes of a given node first.</p>

<h3 id="implementation-5">Implementation</h3>

<p>We can implement the algorithm using a queue, a very common error for
candidates is apparently to assume that this can be implemented recursively.
However if you think about it this canâ€™t make sense, because you would
need to step side-ways in your recursion tree rather than downwards,
introducing another variable to keep a track of where you are! This could
get very complicated, and itâ€™s much much simpler to go iteratively.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">queue</span> <span class="kn">import</span> <span class="n">Queue</span>


<span class="k">def</span> <span class="nf">visit</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">visited</span><span class="p">):</span>
    <span class="n">visited</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>


<span class="k">def</span> <span class="nf">bfs</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">visited</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">queue</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""Operates on Graph objects"""</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">visited</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">visited</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">False</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">}</span>
       
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
    
    <span class="n">visit</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span>
    
    <span class="k">while</span> <span class="n">q</span><span class="p">:</span>
        <span class="n">node_to_visit</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

        <span class="c1"># visit child nodes, then put them in queue
</span>        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">[</span><span class="n">node_to_visit</span><span class="p">]:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">visited</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
                <span class="n">visit</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span>
                <span class="n">q</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analysis-5">Analysis</h3>

<p>This will actually have the same average runtime as breadth first search as
the same operation is taking place. The worst case will depend on your
application though, as discussed above.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope youâ€™ve enjoyed this whirlwind tour of some concepts in Computer
Science, in all honesty this has served as a revision exericise for me.
However I had fun writing it, and explaining something really makes you
question your own understanding. I will be doing another post in the near
future, doing the same thing but for atomic data structures.</p>
:ET